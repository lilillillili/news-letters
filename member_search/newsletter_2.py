import os
import requests
from bs4 import BeautifulSoup
import openpyxl
from datetime import datetime, timedelta
from difflib import SequenceMatcher # âœ¨ ì¶”ê°€ë¨: ìœ ì‚¬ë„ ì¸¡ì •ì„ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬

# -------------------- [ì„¤ì •ê°’] --------------------

MEMBER_XLSX_FILENAME = "memberlist.xlsx"
MAX_NEWS_PER_COMPANY = 5
STOCK_KEYWORDS_TO_EXCLUDE = ["ì£¼ê°€", "ì¦ì‹œ", "ì½”ìŠ¤í”¼", "ì½”ìŠ¤ë‹¥", "ëª©í‘œì£¼ê°€", "íˆ¬ìì˜ê²¬", "ë§¤ìˆ˜", "ë§¤ë„", "ìƒí•œê°€", "í•˜í•œê°€", "íŠ¹ì§•ì£¼", "ì¦ê¶Œ"]
OUTPUT_HTML_FILENAME = "member_news.html"

# -------------------- [âœ¨ ìƒˆë¡œìš´ ì œëª© ìœ ì‚¬ë„ ë¹„êµ í•¨ìˆ˜] --------------------
def is_similar_by_words(title1, title2, threshold=0.5):
    """ë‹¨ì–´ ì§‘í•©ì˜ ìœ ì‚¬ë„(ìì¹´ë“œ ìœ ì‚¬ë„)ë¥¼ ê³„ì‚°í•˜ì—¬ ì¤‘ë³µ ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤."""
    words1 = set(title1.split())
    words2 = set(title2.split())
    
    if not words1 or not words2:
        return False
        
    intersection = len(words1.intersection(words2))
    union = len(words1.union(words2))
    
    similarity = intersection / union if union > 0 else 0
    
    return similarity >= threshold

# -------------------- [ë‚ ì§œ ì…ë ¥ í•¨ìˆ˜] --------------------
def get_date_input(prompt, default_date):
    """ì‚¬ìš©ìë¡œë¶€í„° ë‚ ì§œë¥¼ YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ì…ë ¥ë°›ìŠµë‹ˆë‹¤."""
    while True:
        date_str = input(f"{prompt} (ì˜ˆ: {default_date}) [ê¸°ë³¸ê°’: {default_date}]: ").strip()
        if not date_str:
            return default_date
        try:
            datetime.strptime(date_str, "%Y-%m-%d")
            return date_str
        except ValueError:
            print("âŒ ë‚ ì§œ í˜•ì‹ì´ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. YYYY-MM-DD í˜•ì‹ìœ¼ë¡œ ë‹¤ì‹œ ì…ë ¥í•´ì£¼ì„¸ìš”.")

# -------------------- [1ë‹¨ê³„: ì—‘ì…€ì—ì„œ íšŒì›ì‚¬ ì´ë¦„ ì½ê¸°] --------------------
def get_member_names(filename):
    """ì§€ì •ëœ ì—‘ì…€ íŒŒì¼ì˜ Cì—´ì—ì„œ íšŒì›ì‚¬ ëª©ë¡ì„ ì½ì–´ì˜µë‹ˆë‹¤."""
    try:
        workbook = openpyxl.load_workbook(filename)
        sheet = workbook.active
        names = [row[2].value for row in sheet.iter_rows(min_row=2) if row[2].value and row[1].value]
        print(f"âœ… ì—‘ì…€ íŒŒì¼ì—ì„œ ì´ {len(names)}ê°œì˜ íšŒì›ì‚¬ë¥¼ ì°¾ì•˜ìŠµë‹ˆë‹¤.")
        return names
    except FileNotFoundError:
        print(f"âŒ ì˜¤ë¥˜: '{filename}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì´ì¬ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return None
    except Exception as e:
        print(f"âŒ ì—‘ì…€ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None

# -------------------- [2ë‹¨ê³„: íšŒì‚¬ ì´ë¦„ìœ¼ë¡œ êµ¬ê¸€ ë‰´ìŠ¤ ê²€ìƒ‰ (âœ¨ìˆ˜ì •ë¨)] --------------------
def search_google_news(company_name, count, start_date, end_date):
    """ë‰´ìŠ¤ ê²€ìƒ‰ í›„, í•µì‹¬ ë‹¨ì–´ ê¸°ë°˜ìœ¼ë¡œ ì¤‘ë³µì„ ì œê±°í•˜ê³  ìµœì‹ ìˆœìœ¼ë¡œ ì •ë ¬í•©ë‹ˆë‹¤."""
    print(f"-> '{company_name}' ê´€ë ¨ ë‰´ìŠ¤ë¥¼ ê²€ìƒ‰í•©ë‹ˆë‹¤... ({start_date}~{end_date})")
    
    exclude_query = " ".join([f'-"{keyword}"' for keyword in STOCK_KEYWORDS_TO_EXCLUDE])
    search_query = f'"{company_name}" {exclude_query} after:{start_date} before:{end_date}'
    encoded_query = requests.utils.quote(search_query)
    url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"
    
    try:
        response = requests.get(url, timeout=10)
        response.raise_for_status()
        
        soup = BeautifulSoup(response.text, "xml")
        items = soup.find_all("item", limit=count * 3) # ì¤‘ë³µ ì œê±°ë¥¼ ìœ„í•´ 3ë°°ìˆ˜ ê²€ìƒ‰
        
        candidate_news = []
        for item in items:
            raw_title = item.title.text if item.title else ""
            title = raw_title.rsplit(' - ', 1)[0].strip() if ' - ' in raw_title else raw_title
            if not title: continue

            link = item.link.text if item.link else "#"
            press = item.source.text if item.source else "ì–¸ë¡ ì‚¬ ë¶ˆëª…"
            pub_date_str = item.pubDate.text if item.pubDate else ""
            
            dt_obj = None
            if pub_date_str:
                try:
                    dt_obj = datetime.strptime(pub_date_str.replace(" GMT", ""), "%a, %d %b %Y %H:%M:%S")
                    date_formatted = dt_obj.strftime("%m/%d")
                except ValueError:
                    date_formatted = "ë‚ ì§œ ì˜¤ë¥˜"
            
            candidate_news.append({
                "title": title, "link": link, "press": press,
                "date": date_formatted, "datetime_obj": dt_obj
            })
        
        # âœ¨ ìˆ˜ì •ë¨: ìƒˆë¡œìš´ ì¤‘ë³µ ì œê±° ë¡œì§
        unique_news = []
        for news_item in candidate_news:
            is_duplicate = False
            # ì´ë¯¸ ì¶”ê°€ëœ ÑƒĞ½Ğ¸ĞºĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ ê¸°ì‚¬ë“¤ê³¼ ì œëª© ë¹„êµ
            for unique_item in unique_news:
                if is_similar_by_words(news_item["title"], unique_item["title"]):
                    is_duplicate = True
                    break
            if not is_duplicate:
                unique_news.append(news_item)
            
            if len(unique_news) >= count:
                break
        
        # ë‚ ì§œ ìµœì‹ ìˆœìœ¼ë¡œ ìµœì¢… ì •ë ¬
        unique_news.sort(key=lambda x: x["datetime_obj"] or datetime.min, reverse=True)
        return unique_news
        
    except requests.exceptions.RequestException as e:
        print(f"ì˜¤ë¥˜: '{company_name}' ë‰´ìŠ¤ ê²€ìƒ‰ ì¤‘ ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []
    except Exception as e:
        print(f"ì˜¤ë¥˜: '{company_name}' ë‰´ìŠ¤ íŒŒì‹± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return []

# -------------------- [3ë‹¨ê³„: HTML í…Œì´ë¸” ìƒì„±] --------------------
def generate_member_news_html(all_news_data):
    """ì „ì²´ ë‰´ìŠ¤ ë°ì´í„°ë¥¼ ë°›ì•„ ë™ì  rowspanì„ ì ìš©í•œ HTML í…Œì´ë¸”ì„ ìƒì„±í•©ë‹ˆë‹¤."""
    html_content = f"""
<!DOCTYPE html>
<html lang="ko">
<head>
    <meta charset="UTF-8">
    <title>íšŒì›ì‚¬ ì´ìŠˆ</title>
</head>
<body>
<table width="800" border="0" cellpadding="0" cellspacing="0" align="center">
    <tbody>
        <tr>
            <td colspan="4" height="50" style="background-color: #f8f9fa; color:#333; font-size:16px; font-weight: 700; padding-left:15px; border-top: 2px solid #305eb3;">
                í‘œ2. íšŒì›ì‚¬ ì´ìŠˆ
            </td>
        </tr>
        <tr>
            <td colspan="4" valign="top">
                <table border="0" cellpadding="0" cellspacing="0" width="100%" style="border-bottom:1px solid #e2e2e2">
    """

    for company_name, articles in all_news_data.items():
        if not articles:
            articles = [{"title": "í•´ë‹¹ ê¸°ê°„ì— ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.", "link": "#", "press": "", "date": ""}]
        
        rowspan = len(articles)
        
        for i, article in enumerate(articles):
            html_content += "<tr>\n"
            if i == 0:
                html_content += f'''
    <td rowspan="{rowspan}" style="background-color: #f9f7ff;text-align: center;font-size:13px;color:#305eb3;font-weight:700;border-top:1px solid #e2e2e2" width="120" valign="middle">
        {company_name}
    </td>
'''
            if "ê´€ë ¨ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤" in article["title"]:
                 html_content += f'''
    <td colspan="3" style="padding:10px;border-top:1px solid #e2e2e2;color:#777;font-size:13px;">
        {article["title"]}
    </td>
'''
            else:
                html_content += f'''
    <td style="padding:10px;border-top:1px solid #e2e2e2">
        <a href="{article["link"]}" target="_blank" style="text-decoration: none;color:#222;font-size:13px;">{article["title"]}</a>
    </td>
    <td width="100" style="background-color: #f5f5f5;text-align: center;font-size:13px;color:#222;border-top:1px solid #e2e2e2">
        {article["press"]}
    </td>
    <td width="60" style="background-color: #f5f5f5;color:#222222;text-align: center;font-size:13px;border-top:1px solid #e2e2e2">
        {article["date"]}
    </td>
'''
            html_content += "</tr>\n"
            
    html_content += """
                </table>
            </td>
        </tr>
    </tbody>
</table>
</body>
</html>
    """
    return html_content

# -------------------- [ë©”ì¸ ì‹¤í–‰ ë¶€ë¶„] --------------------
def main():
    """ìŠ¤í¬ë¦½íŠ¸ì˜ ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    today = datetime.now().date()
    default_start_date = (today - timedelta(days=7)).strftime("%Y-%m-%d")
    default_end_date = today.strftime("%Y-%m-%d")

    print("--- ë‰´ìŠ¤ ê²€ìƒ‰ ê¸°ê°„ ì„¤ì • ---")
    start_date = get_date_input("ì‹œì‘ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš”", default_start_date)
    end_date = get_date_input("ì¢…ë£Œ ë‚ ì§œë¥¼ ì…ë ¥í•˜ì„¸ìš”", default_end_date)
    print("--------------------------\n")

    script_dir = os.path.dirname(os.path.abspath(__file__))
    member_xlsx_path = os.path.join(script_dir, MEMBER_XLSX_FILENAME)
    
    company_names = get_member_names(member_xlsx_path)
    
    if company_names is None:
        print("í”„ë¡œì„¸ìŠ¤ë¥¼ ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    all_news_data = {}
    for name in company_names:
        news = search_google_news(name, MAX_NEWS_PER_COMPANY, start_date, end_date)
        all_news_data[name] = news
        
    final_html = generate_member_news_html(all_news_data)
    
    try:
        output_path = os.path.join(script_dir, OUTPUT_HTML_FILENAME)
        with open(output_path, "w", encoding="utf-8") as f:
            f.write(final_html)
        print(f"\nğŸ‰ ì„±ê³µ! '{output_path}' íŒŒì¼ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except IOError as e:
        print(f"\nâŒ ì˜¤ë¥˜: HTML íŒŒì¼ì„ ì €ì¥í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. {e}")

if __name__ == "__main__":
    main()